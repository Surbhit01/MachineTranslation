{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Decoder for Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
    "path = tf.keras.utils.get_file(\"spa-eng.zip\", origin=url, cache_dir=\"datasets\",\n",
    "                               extract=True)\n",
    "text = (Path(path).with_name(\"spa-eng\") / \"spa.txt\").read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\n",
    "pairs = [line.split(\"\\t\") for line in text.splitlines()]\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(pairs)\n",
    "sentences_en, sentences_es = zip(*pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :  How boring! => Qué aburrimiento!\n",
      "2 :  I love sports. => Adoro el deporte.\n",
      "3 :  Would you like to swap jobs? => Te gustaría que intercambiemos los trabajos?\n",
      "4 :  My mother did nothing but weep. => Mi madre no hizo nada sino llorar.\n",
      "5 :  Croatia is in the southeastern part of Europe. => Croacia está en el sudeste de Europa.\n"
     ]
    }
   ],
   "source": [
    "#Printing some samples\n",
    "for i in range(5):\n",
    "    print(f\"{i+1} :  {sentences_en[i]} => {sentences_es[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "max_length = 50\n",
    "\n",
    "text_vec_layer_en = tf.keras.layers.TextVectorization(\n",
    "    vocab_size, output_sequence_length=max_length\n",
    ")\n",
    "\n",
    "text_vec_layer_es = tf.keras.layers.TextVectorization(\n",
    "    vocab_size, output_sequence_length=max_length\n",
    ")\n",
    "\n",
    "text_vec_layer_en.adapt(sentences_en)\n",
    "\n",
    "text_vec_layer_es.adapt([f\"startofseq {s} endofseq\" for s in sentences_es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of english vocabulary : 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'i', 'to', 'you', 'tom', 'a', 'is', 'he']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Length of english vocabulary : {len(text_vec_layer_en.get_vocabulary())}')\n",
    "text_vec_layer_en.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of spanish vocabulary : 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'startofseq', 'endofseq', 'de', 'que', 'a', 'no', 'tom', 'la']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Length of spanish vocabulary : {len(text_vec_layer_es.get_vocabulary())}')\n",
    "\n",
    "text_vec_layer_es.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 50), dtype=int64, numpy=\n",
       "array([[4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]], dtype=int64)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Max sentence length = 50\n",
    "#Corresponding index of the word is stored in an array of length = max_length \n",
    "s1 = text_vec_layer_es([\"de\"])\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 50), dtype=int64, numpy=\n",
       "array([[4, 9, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]], dtype=int64)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Max sentence length = 50\n",
    "#Corresponding index of the word is stored in an array of length = max_length\n",
    "s2 = text_vec_layer_es([\"de la no\"])\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train - first 100000 sentences from english data \n",
    "X_train = tf.constant(sentences_en[:100000])\n",
    "\n",
    "#X_valid - 100000 - last sentences from english data \n",
    "X_valid = tf.constant(sentences_en[100000:])\n",
    "\n",
    "#X_train_dec - startofseq {sent} for first 100000 sentences from spanish data \n",
    "X_train_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[:100000]])\n",
    "\n",
    "#X_train_dec - startofseq {sent} for 100000 to last sentences from spanish data\n",
    "X_valid_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[100000:]])\n",
    "\n",
    "#See previous cell for example\n",
    "Y_train = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[:100000]])\n",
    "Y_valid = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[100000:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "encoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "decoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_ids = text_vec_layer_en(encoder_inputs)\n",
    "decoder_input_ids = text_vec_layer_es(decoder_inputs)\n",
    "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
    "                                                    mask_zero=True)\n",
    "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
    "                                                    mask_zero=True)\n",
    "encoder_embeddings = encoder_embedding_layer(encoder_input_ids)\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.layers.LSTM(512, return_state=True)\n",
    "encoder_outputs, *encoder_state = encoder(encoder_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
    "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
    "Y_proba = output_layer(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 2105s 671ms/step - loss: 2.7791 - accuracy: 0.4450 - val_loss: 2.0657 - val_accuracy: 0.5394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x13117abe820>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                       outputs=[Y_proba])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit((X_train, X_train_dec), Y_train, epochs=1,\n",
    "          validation_data=((X_valid, X_valid_dec), Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence_en):\n",
    "    translation = \"\"\n",
    "    for word_idx in range(max_length):\n",
    "        X = np.array([sentence_en])\n",
    "        X_dec = np.array([\"startofseq \" + translation])\n",
    "        y_proba = model.predict((X, X_dec))[0, word_idx]\n",
    "        predicted_word_id = np.argmax(y_proba)\n",
    "        predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n",
    "        if predicted_word == \"endofseq\":\n",
    "            break\n",
    "        translation += \" \" + predicted_word\n",
    "    return translation.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tf_model():\n",
    "    model = tf.keras.models.load_model(\"..\\Models\\TranslationBiRnn\")\n",
    "    return model\n",
    "\n",
    "model = load_tf_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'me gusta la música'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"I like music\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bidirectional RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "encoder = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(256, return_state=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs, *encoder_state = encoder(encoder_embeddings)\n",
    "encoder_state = [tf.concat(encoder_state[::2], axis=-1),  # short-term (0 & 2)\n",
    "                 tf.concat(encoder_state[1::2], axis=-1)]  # long-term (1 & 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3125/3125 [==============================] - 3542s 1s/step - loss: 2.5902 - accuracy: 0.4727 - val_loss: 1.9252 - val_accuracy: 0.5646\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 3269s 1s/step - loss: 1.6438 - accuracy: 0.6120 - val_loss: 1.5139 - val_accuracy: 0.6366\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 3299s 1s/step - loss: 1.3088 - accuracy: 0.6747 - val_loss: 1.3501 - val_accuracy: 0.6702\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 3252s 1s/step - loss: 1.1158 - accuracy: 0.7128 - val_loss: 1.2868 - val_accuracy: 0.6822\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 3418s 1s/step - loss: 0.9744 - accuracy: 0.7418 - val_loss: 1.2608 - val_accuracy: 0.6872\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 3833s 1s/step - loss: 0.8579 - accuracy: 0.7674 - val_loss: 1.2627 - val_accuracy: 0.6881\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 4055s 1s/step - loss: 0.7597 - accuracy: 0.7890 - val_loss: 1.2804 - val_accuracy: 0.6906\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 4141s 1s/step - loss: 0.6727 - accuracy: 0.8100 - val_loss: 1.3106 - val_accuracy: 0.6897\n",
      "Epoch 9/10\n",
      "3125/3125 [==============================] - 3423s 1s/step - loss: 0.6002 - accuracy: 0.8273 - val_loss: 1.3484 - val_accuracy: 0.6873\n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 2874s 920ms/step - loss: 0.5384 - accuracy: 0.8419 - val_loss: 1.3812 - val_accuracy: 0.6843\n"
     ]
    }
   ],
   "source": [
    "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
    "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)\n",
    "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
    "Y_proba = output_layer(decoder_outputs)\n",
    "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                       outputs=[Y_proba])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit((X_train, X_train_dec), Y_train, epochs=10,\n",
    "          validation_data=((X_valid, X_valid_dec), Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'me gusta el fútbol'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"I like soccer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/TranslationBiRnn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/TranslationBiRnn\\assets\n"
     ]
    }
   ],
   "source": [
    "#Save the model \n",
    "model.save('../Models/TranslationBiRnn') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEAM SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(sentence_en, beam_width, verbose=False):\n",
    "    X = np.array([sentence_en])\n",
    "    X_dec = np.array([\"startofseq\"])\n",
    "    y_proba = model.predict((X, X_dec))[0,0]\n",
    "    top_k = tf.math.top_k(y_proba, k=beam_width)\n",
    "    top_translations = [\n",
    "        (np.log(word_proba), text_vec_layer_es.get_vocabulary()[word_id])\n",
    "        for word_proba, word_id in zip(top_k.values, top_k.indices)\n",
    "    ]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"top first words: \", top_translations)\n",
    "\n",
    "    for idx in range(1,max_length):\n",
    "        candidates = []\n",
    "        for log_proba, translation in top_translations:\n",
    "            if translation.endswith(\"endofseq\"):\n",
    "                candidates.append((log_proba, translation))\n",
    "                continue\n",
    "\n",
    "            X = np.array([sentence_en])\n",
    "            X_dec = np.array([\"startofseq \" + translation])\n",
    "            y_proba = model.predict((X, X_dec))[0,idx]\n",
    "\n",
    "            for word_id, word_proba in enumerate(y_proba):\n",
    "                word = text_vec_layer_es.get_vocabulary()[word_id]\n",
    "                candidates.append((log_proba + np.log(word_proba), \n",
    "                                f\"{translation} {word}\"))\n",
    "                \n",
    "        top_translations = sorted(candidates, reverse=True)[:beam_width]\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Top translations so far:\", top_translations)\n",
    "\n",
    "        if all([tr.endswith(\"endofseq\") for _,tr in top_translations]):\n",
    "            return top_translations[0][1].replace(\"endofseq\", \"\").strip()\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'me gustan los gatos y los perros'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how the model making an error\n",
    "sentence_en = \"I love cats and dogs\"\n",
    "translate(sentence_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "top first words:  [(-0.009752829, 'me'), (-5.1400514, 'yo'), (-6.78987, 'los')]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Top translations so far: [(-0.53081965, 'me gustan'), (-1.1078852, 'me [UNK]'), (-3.4103315, 'me gusta')]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Top translations so far: [(-0.5720572, 'me gustan los'), (-1.3023738, 'me [UNK] los'), (-3.7777119, 'me [UNK] el')]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Top translations so far: [(-0.88856196, 'me gustan los gatos'), (-1.465327, 'me [UNK] los gatos'), (-1.8880031, 'me gustan los perros')]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Top translations so far: [(-1.3661273, 'me gustan los gatos y'), (-2.0261981, 'me [UNK] los gatos y'), (-2.4221363, 'me gustan los perros y')]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Top translations so far: [(-1.6273166, 'me gustan los gatos y los'), (-2.5033646, 'me [UNK] los gatos y los'), (-2.5182374, 'me gustan los perros y los')]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Top translations so far: [(-2.1052697, 'me gustan los gatos y los perros'), (-2.535176, 'me gustan los perros y los gatos'), (-2.5956624, 'me gustan los gatos y los gatos')]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Top translations so far: [(-2.1133938, 'me gustan los gatos y los perros endofseq'), (-2.5869296, 'me gustan los perros y los gatos endofseq'), (-2.6404362, 'me gustan los gatos y los gatos endofseq')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'me gustan los gatos y los perros'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search(sentence_en, beam_width=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention Mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "encoder = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(256, return_sequences=True, return_state=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs, *encoder_state = encoder(encoder_embeddings)\n",
    "encoder_state = [tf.concat(encoder_state[::2], axis=-1),\n",
    "                 tf.concat(encoder_state[1::2], axis=1)]\n",
    "\n",
    "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
    "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_layer = tf.keras.layers.Attention()\n",
    "\n",
    "attention_outputs = attention_layer([decoder_outputs, encoder_outputs])\n",
    "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
    "Y_proba = output_layer(attention_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 2482s 791ms/step - loss: 2.6129 - accuracy: 0.4830 - val_loss: 1.8638 - val_accuracy: 0.5880\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 4522s 1s/step - loss: 1.5980 - accuracy: 0.6329 - val_loss: 1.4751 - val_accuracy: 0.6535\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 3713s 1s/step - loss: 1.3260 - accuracy: 0.6822 - val_loss: 1.3424 - val_accuracy: 0.6802\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 3750s 1s/step - loss: 1.1787 - accuracy: 0.7101 - val_loss: 1.2897 - val_accuracy: 0.6907\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 4147s 1s/step - loss: 1.0688 - accuracy: 0.7307 - val_loss: 1.2623 - val_accuracy: 0.6977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c94921b4c0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                       outputs=[Y_proba])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit((X_train, X_train_dec), Y_train, epochs=5,\n",
    "          validation_data=((X_valid, X_valid_dec), Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'me gusta fútbol y también va a la playa'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"I like soccer and also going to the beach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n",
      "top first words:  [(-0.1095495, 'me'), (-3.8042102, 'prefiero'), (-4.0412292, 'yo')]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Top translations so far: [(-0.22534326, 'me gusta'), (-2.6338477, 'me gustan'), (-4.02202, 'me [UNK]')]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Top translations so far: [(-0.7561035, 'me gusta fútbol'), (-1.2608948, 'me gusta el'), (-3.330087, 'me gustan fútbol')]\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Top translations so far: [(-0.8028421, 'me gusta fútbol y'), (-1.2796283, 'me gusta el fútbol'), (-3.4050558, 'me gustan fútbol y')]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Top translations so far: [(-1.3133388, 'me gusta el fútbol y'), (-1.3273625, 'me gusta fútbol y también'), (-3.476686, 'me gusta fútbol y él')]\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Top translations so far: [(-1.493983, 'me gusta el fútbol y también'), (-1.7836051, 'me gusta fútbol y también va'), (-3.6202354, 'me gusta fútbol y también ir')]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Top translations so far: [(-1.7995749, 'me gusta fútbol y también va a'), (-2.484838, 'me gusta el fútbol y también va'), (-3.3895035, 'me gusta el fútbol y también ir')]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Top translations so far: [(-1.8242681, 'me gusta fútbol y también va a la'), (-2.5024042, 'me gusta el fútbol y también va a'), (-3.4220762, 'me gusta el fútbol y también ir a')]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Top translations so far: [(-1.8312743, 'me gusta fútbol y también va a la playa'), (-2.535354, 'me gusta el fútbol y también va a la'), (-3.4364142, 'me gusta el fútbol y también ir a la')]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Top translations so far: [(-1.8578594, 'me gusta fútbol y también va a la playa endofseq'), (-2.5427785, 'me gusta el fútbol y también va a la playa'), (-3.4434607, 'me gusta el fútbol y también ir a la playa')]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Top translations so far: [(-1.8578594, 'me gusta fútbol y también va a la playa endofseq'), (-2.5656044, 'me gusta el fútbol y también va a la playa endofseq'), (-3.464261, 'me gusta el fútbol y también ir a la playa endofseq')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'me gusta fútbol y también va a la playa'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search(\"I like soccer and also going to the beach\", beam_width=3,\n",
    "            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/Attention/TranslationModel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/Attention/TranslationModel\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('../Models/Attention/TranslationModel') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = text_vec_layer_es.get_config()[\"max_tokens\"]\n",
    "output_sequence_length = text_vec_layer_es.get_config()[\"output_sequence_length\"]\n",
    "vocab_data = text_vec_layer_es.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "x = {\n",
    "  \"max_tokens\": max_tokens,\n",
    "  \"output_sequence_length\":output_sequence_length,\n",
    "  \"vocab_data\": text_vec_layer_es.get_vocabulary()\n",
    "}\n",
    "\n",
    "data = json.dumps(x)\n",
    "\n",
    "f = open(\"../Models/Attention/text_vectorizer.json\", \"a\")\n",
    "f.write(data)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handson",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
